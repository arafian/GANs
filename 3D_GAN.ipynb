{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset\n",
    "from utils import Logger\n",
    "from matplotlib import cm\n",
    "from toySphere import sphere\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training data...\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "# Custom dataloader for 3D spheres dataset, Justin's version with create_noise and add dims  \n",
    "class ToySpheres(Dataset):\n",
    "\n",
    "    def __init__(self, shape, seed, transform=None):\n",
    "        random.seed(seed)\n",
    "        self.data_dir = []\n",
    "        self.dataShape = shape\n",
    "        print('Creating training data...')\n",
    "        for _ in range(shape[0]):\n",
    "            s_x = random.randint(-shape[2]//2 + 2, shape[2]//2 - 2)\n",
    "            s_y = random.randint(-shape[3]//2 + 2, shape[3]//2 - 2)\n",
    "            s_z = random.randint(-shape[4]//2 + 2, shape[4]//2 - 2)\n",
    "            s_r = random.uniform(1.1, 8.0)\n",
    "            self.data_dir.append((s_x, s_y, s_z, s_r))\n",
    "        print('Complete!')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        params = self.data_dir[idx]\n",
    "        model = np.expand_dims(sphere(self.dataShape[2], self.dataShape[3], self.dataShape[4],\n",
    "                                      params[0],\n",
    "                                      params[1],\n",
    "                                      params[2],\n",
    "                                      params[3]), axis=0)\n",
    "        if self.transform:\n",
    "            model = self.transform(model)\n",
    "        return torch.from_numpy(model)\n",
    "    \n",
    "# Load data\n",
    "dataset = ToySpheres((6000, 1, 16, 16, 16), 1)\n",
    "\n",
    "# Create loader with data, so that we can iterate over it\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "# Num batches\n",
    "num_batches = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook initialized with png backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mayavi.mlab\n",
    "\n",
    "mayavi.mlab.init_notebook('png')\n",
    "\n",
    "# Utility for visualizing 3D Data using mayavi\n",
    "#\n",
    "# Arguments:\n",
    "#     voxel_data: ndarray of floats with 3 dimensions\n",
    "#     thresh: float threshold value (all voxels above thresh are plotted)\n",
    "#     percentile: if threshold is negative (not provided) use the given percentile\n",
    "#                 to determine a dynamic threshold for this ndarray\n",
    "#     color: 3-tuple of floats representing (r, g, b) color to plot voxels\n",
    "# Returns:\n",
    "#     mayavi points3d plot (if the final line of a jupyter notebook cell is a\n",
    "#     call to this function, then the plot will be displayed as output)\n",
    "#     Again, the plot will only be shown if the call to this function is the\n",
    "#     last line of the cell.\n",
    "def visualize3D(voxel_data, thresh=-1.0, color=(0, 1, 0), percentile=0.8):\n",
    "    mayavi.mlab.clf()\n",
    "    if thresh < 0:\n",
    "        ordered_data = voxel_data.copy().reshape(-1)\n",
    "        ordered_data.sort()\n",
    "        thresh = ordered_data[int(len(ordered_data)*percentile)]\n",
    "    c, xx, yy, zz = np.where(voxel_data > thresh)\n",
    "    plot = mayavi.mlab.points3d(xx, yy, zz,\n",
    "                         mode=\"cube\",\n",
    "                         color=color,\n",
    "                         scale_factor=1)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" alt=\"PNG image\"></img>"
      ],
      "text/plain": [
       "<mayavi.modules.glyph.Glyph at 0x7f38b0cf6200>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sphere = dataset[12].detach().numpy()\n",
    "visualize3D(test_sphere, color=(0,1,1), thresh= 0.1)\n",
    "visualize3D(test_sphere, color=(0,1,0), thresh= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            # start with a 16x16x16 model (1 channel)\n",
    "            nn.Conv3d(in_channels = 1, out_channels = 64, kernel_size = 3, stride = 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            # now 14x14x14\n",
    "            nn.Conv3d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            # 12x12x12\n",
    "            nn.MaxPool3d(2, stride=2)\n",
    "            # 6x6x6\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            # 6x6x6\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            # 4x4x4\n",
    "            nn.Conv3d(in_channels = 16, out_channels = 1, kernel_size = 3, stride = 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            # 2x2x2\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(8, n_out),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        # reshape 2x2x2 model to vector of length 8\n",
    "        x = x.reshape(x.shape[0], 8)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "discriminator = DiscriminatorNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = 100\n",
    "        n_out = 784\n",
    "        \n",
    "        self.linear = nn.Linear(n_features, 343)\n",
    "        # 7x7x7\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        # 14x14x14\n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1, padding = 2),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        # 16x16x16\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        # 16x16x16\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        # 16x16x16\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 8, out_channels = 1, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1x100\n",
    "        x = self.linear(x)\n",
    "        # 1x343\n",
    "        x = x.reshape(x.shape[0], 1, 7, 7, 7)\n",
    "        # 1x7x7x7\n",
    "        x = self.upsample(x)\n",
    "        # 1x14x14x14\n",
    "        x = self.hidden0(x)\n",
    "        # 32x16x16x16\n",
    "        x = self.hidden1(x)\n",
    "        # 16x16x16x16\n",
    "        x = self.hidden2(x)\n",
    "        # 8x16x16x16\n",
    "        x = self.out(x)\n",
    "        # 1x16x16x16\n",
    "        return x\n",
    "\n",
    "generator = GeneratorNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    '''\n",
    "    Generates a 1-d vector of gaussian sampled random values\n",
    "    '''\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data\n",
    "\n",
    "def zeros_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    N = real_data.size(0)\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = loss(prediction_real, ones_target(N) ) # try to modify prediction back to vectors\n",
    "    error_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = loss(prediction_fake, zeros_target(N))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error and predictions for real and fake inputs\n",
    "    return error_real + error_fake, prediction_real, prediction_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optimizer, fake_data):\n",
    "    N = fake_data.size(0)\n",
    "\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "\n",
    "    # Calculate error and backpropagate\n",
    "    error = loss(prediction, ones_target(N))\n",
    "    error.backward()\n",
    "\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # Return error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 16\n",
    "test_noise = noise(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arafian-admin/env/lib/python3.5/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/200], Batch Num: [0/60]\n",
      "Discriminator Loss: 1.3947, Generator Loss: 0.7584\n",
      "D(x): 0.4648, D(G(z)): 0.4665\n",
      "Epoch: [1/200], Batch Num: [0/60]\n",
      "Discriminator Loss: 1.7345, Generator Loss: 0.4253\n",
      "D(x): 0.5746, D(G(z)): 0.6693\n",
      "Epoch: [2/200], Batch Num: [0/60]\n",
      "Discriminator Loss: 0.7778, Generator Loss: 4.5732\n",
      "D(x): 0.5508, D(G(z)): 0.0810\n"
     ]
    }
   ],
   "source": [
    "# Create logger instance\n",
    "logger = Logger(model_name='3DVGAN', data_name='3DMNIST')\n",
    "\n",
    "# Total number of epochs to train\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, (real_batch) in enumerate(data_loader):\n",
    "        # this will be 100 since batch_size is 100 as defined earlier\n",
    "        N = real_batch.size(0)\n",
    "\n",
    "        # 1. Train Discriminator\n",
    "        # real_data = Variable(images_to_vectors(real_batch))\n",
    "        real_data = Variable(real_batch) # don't switch this time\n",
    "\n",
    "        # Generate fake data and detach \n",
    "        # (so gradients are not calculated for generator)\n",
    "        fake_data = generator(noise(N)).detach()\n",
    "\n",
    "        # Train D\n",
    "        d_error, d_pred_real, d_pred_fake = \\\n",
    "              train_discriminator(d_optimizer, real_data, fake_data)\n",
    "\n",
    "        # 2. Train Generator\n",
    "\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(N)) \n",
    "\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data)\n",
    "\n",
    "        # Log batch error\n",
    "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
    "\n",
    "        # Display Progress every few batches\n",
    "        if (n_batch) % 30 == 0: \n",
    "\n",
    "            #logger.log_images(\n",
    "            #    test_images, num_test_samples, \n",
    "            #    epoch, n_batch, num_batches\n",
    "            #);\n",
    "            \n",
    "            # Display status Logs\n",
    "            logger.display_status(\n",
    "                epoch, num_epochs, n_batch, num_batches,\n",
    "                d_error, g_error, d_pred_real, d_pred_fake\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
